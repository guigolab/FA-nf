// Uncomment or modify the parameters below to fit your dataset and setup choices
params {
 // Protein fasta input
 proteinFile = "${baseDir}/dataset/P.vulgaris.proteins.fa"
 // GFF input
 gffFile = "${baseDir}/dataset/P.vulgaris.gff3"
 // Whether to run pipeline in debug mode or not
 debug = "true"
 // Whether to check and clean GFF input file
 gffclean = true
 // Whether to generate stats from GFF input file
 gffstats = true
 // Processing sizes below
 // Number of protein sequences per chunk (used as fallback)
 chunkSize = 25
 // Number of protein sequences per chunk when using BLAST (or DIAMOND)
 // You can normally use a far higher number if using DIAMOND
 chunkBlastSize = 50
 // Number of protein sequences per chunk when using InterProScan
 chunkIPSSize = 25
 // Number of protein sequences per chunk when using KofamKOALA
 chunkKoalaSize = 50
 // Number of protein sequences per chunk when submitting to web processes (CD-Search for now)
 chunkWebSize = 100
 // Number of chunks to be used when running in debug mode (e.g., for facllback processes this would be 5*25=125 protein sequences)
 debugSize = 5
 evalue = "0.00001"
 diamond = true
 // Blast DB. Details to retrieve from: https://github.com/toniher/biomirror/tree/master/files/ncbi
 blastDbPath = "/nfs/db/ncbi/201908/blastdb/db/nr"
 // Instance from where to retrieve GO mappings. You can set up your own from: https://github.com/toniher/gogoAPI
 gogourl = "http://gogo.test.crg.eu/api"
 // Maximum number of hits to consider (up to 30 by default))
 // gogohits = 30
 // Modes of retrieval from BLAST matches (common, most, all)
 blastAnnotMode = "common"
 speciesName = "P.vulgaris"
 // Pre-downloaded OBO file with GO descriptions. Otherwise pipeline will download it
 oboFile = "${baseDir}/dataset/gene_ontology_ext.obo"
 // Directory where to store intermediary Interproscan files (ensure there is enough space)
 ipscantmp = "${baseDir}/tmp/"
 // Kegg species codes to retrieve ortholog information. Codes from: https://www.genome.jp/kegg/catalog/org_list.html
 kegg_species = "hsa, dme, cel, ath, sce, cho, eco, nme, hpy, rpr, bsu, lla, cac, mge, mtu, ctr, bbu, syn, bth, dra, aae, mja, ape, aly, cit, tcc, gmx, fve, csv, vvi, sly, osa, olu, ota, mis, cme, gsl"
 // Profiles and KEGG codes list from ftp://ftp.genome.jp/pub/db/kofam/
 kolist = "/nfs/db/kegg/ko_list"
 koprofiles = "/nfs/db/kegg/profiles"
 // KO entries. Can be retrieved in advance using: https://github.com/toniher/biomirror/tree/master/files/kegg
 koentries = ""
 // Database engine. Specify MySQL (otherwise 'SQLite' will be used)
 // dbEngine = "MySQL"
 // Database name. If it does not exist, if the user has enough permissions it will be created
 dbname = "Pvulgaris"
 // Database user name
 // dbuser = "test"
 // Database user password
 // dbpass = "test"
 // Port of the MySQL engine (3306 default)
 // dbport = 12345
 // The host where the MySQL engine is located. Skip it if using the MySQL wrapper
 // dbhost = 0.0.0.0
 // If using the wrapper below, where MySQL data will be stored
 // mysqldata = "${baseDir}/mysql/"
 // If using the wrapper below, where MySQL instance logs will be stored
 // mysqllog = "${baseDir}/tmp/"
 // If using the wrapper below, which Singularity/Docker image will be used
 // mysqlimg = "docker://library/mariadb:10.3"
 // Where results are stored
 resultPath = "${baseDir}/results/"
 // Where log files are stored
 stdoutLog = "${baseDir}/logs/functional_annotation.stdout"
 stderrLog = "${baseDir}/logs/functional_annotation.stderr"
 // Logging verbosity for some data upload processes
 loglevel = "info"
 // Uncomment and put your mail if your setup allows sending emails
 // email = "yourmail@yourdomain"
 // Comment the lines below to execute those analyses
 skip_cdSearch = true
 skip_sigtarp  = true
}
